leprechaun software engineering

so let's get started and I haven't heard the bell ring yet but I don't know if that's going on at this time anyway so this is it this is the last day of conference soon be going home feeling kind of sad to leave here it's been a great week so was anyone at the talk talk I did yesterday no great so no fur lapping audiences which means I'll be making new acquaintances right so this is kind of a mysterious title that I will explain in a moment the leprechauns of software engineering so who is the software engineer not so very many of you all right so maybe this is kind of superfluous but still a lot of what we do in software development is seen as belonging to that particular discipline software engineering and many of the things we talk about in the adult community take place within the context of a debate which started in the late 60s 1968 was to date when people came up with this notion that there is a there is such a thing as software there are some disciplines concerned with the engineering of various things so why not apply the notion of engineering to software and this was born software engineering that was not something which came naturally initially the phrase was seen as provocative that's another talk when I've given before in the history of software engineering and the continuity between the history of software and engineering and that of a draw but I wanted to briefly bring some of that background to this talk now a different kind of history when I was a kid used to read the comics any of you remember that no the killing books and comic comics that you read as a kid and it was not oh you know it was not all adventure comics or funny comics there were also things of a more educational interest and one of the things I used to like a lot was the did you know section so I don't know if that rings a bell for you but interesting factoids things about the world 
that may waken the curiosity of a young person and 

they're one of the things 

I came across was this notion that we only use 10% of our brains 
so did you know scientists have shown that people use only 10% of their brains 
another fun one was did you know that the Great Wall of China is the only man-made structure that you can see from space 
actually this has you know kind of inspired other vocations 

but the key thing (of course ) about those two things facts so-called is that 
there are not actually fact 
neither of them is actually true we don't know enough about neuroscience to be even able to make such statements as how much of our brain we actually use 
we use all of it the brain is kind of a holographic thing 
so that statement doesn't really make sense 
it was probably derived and distorted from something that somebody said at some point which transformed into something else 


the same goes for the story about the Great Wall of China there are many man-made structures that you can see from space if you interpret space as certain altitude and there you can see nothing if you go high enough right so that's you know the the kind of thing I used to to be tricked into believing and then found out much to my annoyance embarrassment were not actually true so a great resource if at any point in your life because they did to my again to my disappointment and surprise I keep learning that some things I believe our force even at the old age well had the middle age of 40 so I period periodically check something up on Snopes comm which is a site devoted to debunking urban myths so what's interesting is I think we need a snopes.com for things in software engineering so things that people will tell you but which in fact turn out not to be true so I'm going to be telling you today about things I have come to call leprechauns while Ypres can I get through that in a moment but I want to start with a concrete example so isn't this something we would all like to know where do bugs come from and I I advanced a theory a hypothesis about that yesterday in my other talk which was that blogs in the source code tend to come from bugs in the human brain those we call cognitive biases but there is a different kind of explanation which goes around for and has been kicking kicking around for many years now in the software engineering community and it goes something like this you can probably use Google to find a very close approximation to that code 50 56 percent of all bugs identified in in projects across the whole industry originated in the requirements phase that's something i've read time and again so of course the thing to remember is that this is folklore it's myth it's not fact and actually it cannot even be fact it's not possible for this to be a fact but I will I will come back to that now I'll tell you the results of that investigation but I think when when you come across something like that which is a sweeping generalization which has a number in it so that would seem to indicate that some kind of research was done at one point and that is you know kind of an aggregate result from many projects so you think there were studies and several of these studies were summarized into that one number but so a very useful and healthy thing to do when you come across such a claim is something that has been encapsulated in the Wikipedia community as citation needed that's the phrase they use and there is this very nice illustration from the comic xkcd if you don't read xkcd you might find it interesting funny at times funny in a tragic sort of way so is someone who really gets what it is to be a geek and so he's got a geek all over his work so politicians are very prone to that kind of thing they will say something with toys aspirins I say that jobs in this country are being destroyed because of blah blah blah and nobody usually things to ask them in you know in the moment wait how do you know that do you have proof do you have evidence so that that's the kind of thing that the xkcd author is dreaming about someone waving a placard saying what is your evidence give us a citation but the more disturbing thing I think about the 56% claim is when when I personally express disagreement with those kind of things I tend to get a response which goes something like this so so I made the claim starker more clearly false so that you can see the logic so say someone is telling me 56% of all bugs in our programs are in fact introduced by a leprechaun called Murphy and you know sometimes it feels a little like that where did this book come from certainly not from me it worked on my machine so so this may even feel like a correct explanation for bugs they are introduced into our source code by gremlins or leprechauns or something like that but then of course you know you wake up and no no clearing that's that's not the case so you would you'd raise your hand and say what no this is this is a false claim and then the person you were talking to says oh you think you think it's false so so you think it's more than 50 56 percent that comes from leprechauns or maybe less than 56 percent and of course the answer to that is no it's not the number that matters it's there are no such thing as leprechauns right so that's you know that's that's the analogy that came to mind when I had this kind of discussion and that's the reason I coined the term leprechauns so I had used this skeptical thinking reflex when I was confront confronted with that claim that 56% of all bugs come from the requirements face this is this is not just you know something that people say which doesn't matter it's it's actually it turns out to be a pretty big deal because if you think about the justification for the waterfall cycle initially was that because there were two things which kind of underpinned the waterfall cycle one of them was I will come back to that if you don't catch a mistake in the requirements it's going to cost you a lot more to fix it later when you get to the coding phase and the other was most of the mistakes in fact confirm requirements so if you were convinced of those things you would be very well justified it would be a smart conclusion to come to that we must act requirements work very seriously we must invest most of our effort there and and certainly not rush to programming all right so do the do a lot of work up front in the upfront phase because studies have shown you know researchers tell us well people tell us that researchers say that's where the mistakes happen and that's when it's cheapest to fix so that's that's a legitimate conclusion if the premise is true and because it's so important it's important to check where that comes from so where is the evidence where is the original original study so I started digging around using the citation needed reflux and it turns out that most of the people who are currently saying this are referencing someone else so there are there are some citations with our usually citations to someone who's citing someone else again so what do you do as good programmers you recurse right so you want you want to see where that thing bottoms out so you go looking for the citations that that you go up the chain of citations and you find someone who says one study by James Martin showed that so it's no longer you know it's it's not Oh many researchers have worked on this and come up with that one number as a summary it's one person James Martin in one book but that at least has the benefit of narrowing things down so you go and try to get that book it's not easy because it's out of print for decades it's a book called I forget the exact title it's a book from the 60s I think by James Martin and the nice thing now is you can actually order use books on Amazon and you can get them for very cheap because they are used library books which are returned to circulation through Amazon Marketplace by book sellers so it's it's books that libraries are getting rid of basically so I got this one for I think 2 euros and so I'm referring to the pages trying to find the source of this observation how many studies how many scientists were involved how many projects how many do you think what do you think was the sample size to use the technical term for that study which showed that 56% of all bugs in projects come from requirements I guess of course so this is a statistical result so the bigger the sample size the more convincing this should be any guess so 10 okay that if you came across the study that say we studied 10 projects and we came to that conclusion would you think it very convincing not a lot how many would it take to convince you something in the hundreds maybe yeah that's I don't know why because it depends on so many other things but we would probably tend to be more convinced if someone came and told us we study the 100 projects across many different kinds of enterprises and this is what came out but actually spare you the hunt for the exact detail the simple science was one so it's this one company that James Martin was working with it's a bank and and it's I mean he's not a scientist he's a consultant so that very widely cited figure of 56% turns out to be almost not you know not quite but almost made up and yes it's used as a critical for many things in software engineering hmm so we're going to keep we're going to keep track of Murphy and this is kind of a you know I'm just taking you on a tour so I'm we only have a short span of time so I can only give you a few highlights hopefully we'll have some time at the end to take questions so be aware that there are more sites to see on this exploration of leprechauns in software engineering I'm just giving you some highlights the cost of change how many of you are familiar with the Ken Beck's book on extreme programming a few so you will remember this that's the famous fabled cost of change curve so now the interesting thing in extreme programming in in the theory of extreme programming is the claim that extreme programming flattens the cost of change curve but I'm not going to talk about that I just want to focus on this and where it came from so what this says if you look at the curve in terms of what does it mean so what's on the bottom this the phases of the life cycle so it's the one thing to notice is the curve is smooth it's continuous as if the bottom axis was something more continuous like time but you know it's actually a discrete curve and the y-axis is a cost so the unit would be what money except except of course that in in the software business we don't count cost in terms of money most of the time we write so you know that's already something that the dirt good would be interested in finding the details when this was measured right because this is the graph so it's probably something that came out of some studies it would be interesting to see if the data points were come came from hours or dollars or some other unit but so those are just a few of the questions that might pop into your head when you see something like that now Beck says in his book he's very honest he says I drew this from memory and from memory of my university days so I got this from the teacher and you know maybe I'm not drawing it quite right but you get the general idea which is that it costs more to make a change in a software project time or you know kind of a circuit of time which is the the phases of the life cycle goes on so that's why that's where I first came across that curve because I'm a fairly young developer some of the people who have been around for longer probably so it originally in a different form so I'm just going to show you the oldest form of that curve and and you notice the difference this one is linear whereas sorry the previous one was a an exponential but of course this is a log graph which is why so linear art corresponds to a log curve when you well I mean a linear slope on a log graph corresponds to an exponential so this one is more interesting because you can see there are there error bars that's 

that's good right you it's a scientist being honest we measured but you know we are giving you a kind of a summary of those measurements and and there is some uncertainty so we saw measurements that ranged from this to that but yeah roll it seems to be a very very nice fit so the originator of that curve is Mary boehm but there you probably notice another difference any one spot that so this is not the cost of change curve this isn't this does not talk about right so this one is about fixing defects so 1976 what boehm was saying then was something slightly different or may be significantly different depends on how you interpret that from what Beck was saying in 2000 so the original finding was if you if you take so if you take if you divide the cost so we suppose it's the average cost to fix a bug when you detect it here and you compare it to the cost to fix the same bug when you detect it earlier in in the design phase you get a ratio so that that curve is a curve it's a plot of ratios so that's why it's really relative cost to fix curve and you you see this everywhere I mean there are tens and maybe hundreds of citation of that finding in various forms so this is one of the more exotic forms it's the pyrrha made an interpretation of the cost to fix curve but yeah that's you know it's kind of it's a little like the food pyramid so it's 20 years after the original finding and this one is even more elaborate so that's it's something that was published by the US Federal Highway Administration in 2007 and and they say it's inspired by Steve McConnell who has done a lot of work to popularize some important ideas in software engineering and in particular some ideas from boehm and and what this one shows I think it's interesting for that reason it kind of gives you a matrix between when the error was introduced and when it was detected so of course if you if you introduce an error in the coding phase it doesn't quite have time to blow up exponentially but if you introduce a defect in the requirements phase then it has time to go and blow up to more than a hundred times the cost to fix originally in defects yes that's that's an excellent question that's an excellent question so so you guys know bugs right and you know that bugs come in all sorts of varieties and you know and you know that there is a lot of have any of you have that happen that you spend one hour maybe two hours maybe days arguing with the customer whether something was the bug or not a bug has that ever happened to you right so so and we tend to do that for many things it's not just once in the course of a project right it's it's a recurring discussion we spend a lot of time arguing about those things and but the scientists who studied that right they must have have had a clear sense of what was and what wasn't a bug otherwise they couldn't do that research so that there's an interesting debate about that because the original research was in the 70s there were no agile projects but well they were not talked about much anyway and so the model that most people would have in mind and anyway the way that the curve is frame suggests that the projects that they studied were waterfall time projects but what's more interesting is you know so you come across the curve itself and if you have the citation needed reflux you're going to check the data so we want to what you want to say is show me the numbers where are the numbers wrong numbers right so this is do you think this is the same graph a system of you squinting so it doesn't quite jump out at you but this is one of the graphs from a paper by boehm published a few years later which looked in more detail at exactly the same project that this curve purports to describe the one so so TRW survey I don't know if you can read that that the black dots those points are supposed to come from this data more less or rather it's not quite clear because there are two different papers so it's an inference on my part that they were referring to the same project but there is a lot of text in in addition to the pictures which describes where he got the data from and so those are actually students so there were students that Barry boehm was teaching and he took some measurements of how long it took them to do various kinds of work so my question to you is do you see an exponential curve here neither do I so that's you know I came across this paper and it's a lot of research to find them and I was you know hoping to see the data that corresponded to an exponential rise you know maybe not exactly maybe you could see some error bars but I was not expecting to see that you know which is you know just kind of ups and downs and so but that's not the only series of data points in the curve there were others so again you go look for anytime that the curve is used in the serious book you will usually see a lot of citations right and so you can follow the chain of citations back to the source and one of the more serious sources that I came across was this fairly recent paper referring to studies that use hair craft so also a fear is a very serious software installation it's not your you know rinky-dinky startup where you could always say yeah but you know these guys they are not very disciplined so maybe what they do is not representative no this is a this is a big corporation okay so and this is interesting because it's the most detailed account of the raw data that I could find so probably the best in terms of quality of the original data and there may be all sorts of problem doing the measurements and that's also part of my issue with the whole thing but at least you you have numbers so you can check whether the numbers tell the same story that the curve now I'm not going to ask you to infer that from just looking at the numbers I'm going to show you the curve but it's not in the paper it's a that I made using Google spreadsheet no same question as before do you see an exponential there no it's actually cheaper according to use aircraft to fix a defect in maintenance than it is in functional testing contrary to what you know received wisdom and everyone who signs the curve is saying and and so it's actually more expensive to fix a defect in the architecture phase than it is in the design phase so no that's that's not the same story but I've only plotted here one data series if you remember the I can show you the the original data so it's the same matrix that we saw for the from the federal highway graphs so that they are actually tracing the cost of requirements based on when it was introduced and when it was detected you might ask how do they know that the defect was introduced in requirements I don't know yeah I've come back to that I'll come back to that it's it's an interesting observation so let me let me first show you what you know what the source data said and we'll come back to this question of personal experience and what we all know so here again so this is from the other data series and to be frank to be honest I have to admit that at least one series does seem to fit more or less an exponential curve and that's the read so it actually goes off the chart at the top but it's the only data series that does not so if you look at the other ones which so that's for the earliest defects the one introduced in requirements that's the cost of fixing them according to when they are detected and the red is the defects introduced in architecture that's the cost of fixing them according to when you detect and the same for design and code and so on right so there is one which is an exponential and the other ones are well we can see that it's more expensive a little in the later phases but we don't see this exponential the nice smoothly rising exponential that everyone is talking about all right so so my conclusion was that had been more or less taken for a ride tricked into believing something which is at the very least in the best interpretation the the traditional curve is a lot stronger in what it says than the actual data and you can you could probably say that there are many problems in interpreting the actual data because what's a bug how do you measure the cost all of these things are hard so I would expect to see much more than one study before I came to believe an exponential curve so just do to boil this down to a couple takeaways for you don't just demand citations don't just say oh if you show me a citation now I will believe and if you don't I won't believe it's interesting to actually read what people are citing and make you know make your own decision as to whether that is convincing or not convincing and especially when what people are showing you is a chart histogram or a curve what's interesting is not just the overall shape all the conclusions but where did you get this data point what did you measure to get this what does it mean because here is studying students and maybe they do different things at different stages of the project so maybe the way you measure the cost is not the same in requirements as it is in design and testing so are these cost even comparable with each other I don't know we need more signs I'll go quickly over this one because I think it's also interesting it's been used as an argument for agile the cone of uncertainty that's also from McConnell this is a modern representation this is something you would see today in a blog for instance notice it's the same it's the same timeline it references the lifecycle phases and there is a variant which says the best you can do is your initial estimates would be between four times and a quarter what the project eventually costs but that's the best you can do that's if you have very good practices in place and actually your estimate will remain fuzzy until the very end of the project if you don't have good practice so that's the idea that good practices kind of shrink the code do you see a problem with the cone as it is currently shown do you think so so what this says in terms of numbers is you compare it's also a ratio you compare how long the project actually took that's what you know at the end of the project when you ship with your initial estimate and what you find is that your initial estimate may be as much as four times what the project actually took or it may it may be as little as one quarter right so you could be you could be very optimistic or very pessimistic in your initial estimate and that's symmetrical yes so let me ask you how many of you have had a project when you were early by a factor of me just 2/3 one person ok how many of you were I don't need to ask that right and because nobody was early by a factor of four right how many of you were on projects which were allayed by a factor of at least 20% right late that by more than 50% some of you anyone anyone had worked on a project where they were light laid by more than two twice the original estimate okay so right now we have a it's maybe an representative sample but you don't fit the cone right so why where did the original data come from and and why is it that when we Paul smallish but still you might be more or less representative so I looked for the data and interestingly enough that there was a short search because there is no data this is the code I found in berry boehms book software engineering economics a hugely influential book and he says about the graph that is that came to be known as the cone of uncertainty these ranges have been determined subjectively you know what that word means it means I made it up well based on experience so we come back to that thing about experience isn't it the case that we know from experience and common sense that it costs more to fix the defect later sure I could give you thousand arguments white so but then again if you think about we use 10% of our brains we all know people you know where that make us go oh yeah this guy he's using 10% of his brain right don't tell me you haven't ever thought that about someone round you may be higher up than you I don't know but so so many things which are convincing from a personal experience point of view turned out to have no substantial basis and actually there are many bugs which were which even when you detect them very late in the process there are one minute fixes very quick very quick to fix very quick to deploy but what happens to those you forget about them right because they were so easy what stands out in your mind that's the kind of bias availability bias which is for exactly the same reasons that many people fear flying in a plane and the thing they're going to die if they're ever set foot in a plane and so they drive to wherever they go on vacation and they drive to work even though they're about I don't know how many 50 times as likely to die in a car as in a plane but that's availability bias right because you've heard about the plane crash it doesn't even have to be 9/11 every time there is a plane crash people get scared and they prefer to drive instead and more people die that's the way we are wired so just to end that section on a positive note you could get empirical about the uncertainties in a project so this is something from one team and they are measuring this is a burn down chart they are measuring how close they get they are getting to done and there you know there is some uncertainty because there is the streak extrapolation of that curve but it could be better to use an average of the previous velocities or you could try to average the past three velocities and that's where the uncertainty come from do you notice the difference between that and the cone another significant graphical difference they are not oriented the same way so it's interesting that this one is called the cone of uncertainty but it shows it what it says is basically the future gets more certain as we go toward it which is kind of a strange way to say it I think this is more convincing this is we know the past and the present but as we as we move along to the right of that graph or range widens but I just want you to think about that so this is this is an empirical measurement this is from a paper in I Triple E software which was very critical of the cone of uncertainty and said we actually did measurements in our in a company and we measured estimates given at various points and we compared them to how long the project I shall it took and we ended up with something like this which is that you know I am much more convinced by that because it has the right asymmetry we are optimistic most of the time not pessimistic about project duration that's that's more like it you know that's that's better data but it took researchers to become it took researchers who became critical of the cone we became skeptical and they weren't actually looking for the data and they found something that doesn't really fit a cone and maybe there's a lot of follow-up research to do on that you know why is that every are more or less empty and it's it's it's kind of strange the way this plot looks so it makes me want to ask more questions rather than feel you know ok the matter has been settled even though the method of the cone is something I agree with which is don't try at the day one of the project to have very precise estimate because most of the time you'll be way off but you're not going to be way off in the way that the cone says a final one oh well so takeaways you know they're saying one picture is worth a thousand words so you must keep in mind that it goes both ways it's much easier it's a thousand times easier to lie with a picture than it is to lie with words so when you come across a picture you have to ask yourself what a chart or curve or a histogram what does that mean how did they measure what they claim to have measured is that measurement even possible right is it even possible to measure the average cost of fixing a bug given the variety of things we call bug and given the amount of time we spend arguing about whether it's a bug or something else I don't think it's possible I don't know that you know I don't think and I have the same trouble with productivity any study you come across that claims to have measured the effect of something on productivity to me the question that comes to mind immediately is what do you mean by productivity because do you count do you count the people who are actually do you can the hotshot programmer who who writes a thousand lines of code in a day but then you have to spend weeks in the rest of the project for the rest of the team debugging his mess but you know because because he's been hugely productive and the managers and he kind of saved the project in the client-side because he rolled that feature that the client was expecting in one day and the client was hugely impressed the only well it doesn't quite work but well there are just a few bugs will fix them is that very productive I don't know what does that word even mean right so so it's it's really key to think about the meaning of those terms whoops sorry hyper productive scrum that's an interesting one because it's closer to home right it's so it's not a software engineering it's not a traditional software engineering engineering leprechaun it's a natural lip recon oh my what do you we have those two yes we have so this is from control chaos it's one of the founding papers in in scrum scrum methodology similar to the iterative methodology but assuming that all requirements are not known in advance which is a good assumption I approve of that assumption where I have a problem is with the almost the next sentence I just snipped a bit which was not relevant productivity gains of 600 percent have been seen repeatedly in well executed project centers one anecdotal evidence is we've seen this repeatedly and on average six times as fast six times as productive and not just you know it's not just earth saying that it's not the scrum people saying that it's capers Jones have you guys heard of capers Jones he's a so maybe not and maybe you're lucky because I'm not sure he's quite as relevant today as he used to be a little like berry boehm so there are those kinds are economics but he was hugely influential in academic software engineering it seems those guys are like the the Pope's and Cardinals of software engineering so so well so there are two things that you might be convinced by there's a number six times that's good repeatedly so it's not anecdotal and there is an authority backing that Wow let's do scrum can't escape that conclusion scrum is the smart thing to do if you do anything other than scrum then you're likely responsible for failure to get six times productivity you're going to get fired and it's not just the scrum people saying so it's one of the Cardinals of software engineering huh I asked exactly the same question but I'm glad you asked well capers Jones is still alive so I emailed him I couldn't find a source I couldn't find that source in the literature so I sent your parents an email and say hey you don't know me I'm just this guy I'm you're the Cardinal I'm just random actually he's very sweet he's a very sweet person so he took the time to write back to me he he sends me tons of documents about he's he's the Pope of function points I don't know if you've heard of function points but he's the guy who invented them basically so he sent me tons of documents about function points and he said you should learn about function points but he was really sweet and that's what he told me I don't remember that quote activism I almost certainly did not assert that agile had 600 gained person gains because no methods have ever done that and I have looked at many what say again but no I was not actually surprised by that one by that point because I was in the process of writing up my findings I get to that in a minute so leprechauns you find them everywhere right they were you were the agile leprechauns I like I like this quote by Twain it's it's not what you don't know that's going to kill you and your project it's what you know absolutely with total certainty but it's just it's just not true so it's like have you seen those funny videos of people bumping into a glass door there is nothing there so I can just walk straight so that's what gives you right it's it's the things you think are true which just aren't so so if you had to take one key message of course from this it's thing for yourself that's don't have have a reflux of doubt whenever you can even so what I like some of my readers are great I've written this up in a book called the leprechauns of software engineering so we can get more lots more detail about a bunch of other things but you know I really wanted to take the time to dissect a few examples for you I have great readers they write back to me and said in chapter 3 you say this and that can you clarify for me where you get that I'm not sure if it's true you've got it so even even what I tell you you might want to check so I've tried to make my arguments easy to check by including all the references making sure that there are that you know where you can get the papers because some people will cite they will cite a book or a paper at you and it's an out-of-print book or it's a pepper that you have to pay $30 from a tree to a Tripoli to get that's not easy to check I know that I know that it's a difficult proposition to be skeptical I have encountered that in practice time and again it's as if someone has decided that all the knowledge in the world must be locked away you know behind the paywall just in case no knowledge is the dangerous thing right so it wouldn't do for all these people out there all those practitioners to have too easy an access to all the works of researchers academics they've worked so hard on this why should it be easy for you to get right that you know that's not the way progress is made science progress is a matter of disseminating knowledge so that you can be skeptical but you can also have justified belief in the things that it's correct and legitimate to believe so most of the time you will be able to find links to PDFs and can get them under you know more or less legally and that's about it thank you I noticed we have time for questions so that was not one of mine it's something I grabbed from the web from a team that was measuring their scrum which I you know that's a good idea you can you can probably learn a lot from taking a scientific mindset approach with respect to your own project at least you can validate the data so it's a it's a burn down right so part of it is in the past how many points did we have left in scope it's not a very good burn on either it's one of those that start out flat and then woohoo there's a dip people start to complete user stories maybe they were doing too many things in parallel but what I found interesting in this one was the the inversion it's it's kind of flipped around so they used I don't know what best estimate is yes you have to be careful with measurements of estimate accrue see Linda had a great talk where she told us all we need to know about why you cannot really estimate so at best it's something that gives you a way to think more closely about your project but it's not a crystal ball so and and part of our cognitive biases we are very bad at dealing with predictions and probabilities so this is not you know this is not going to be published in academia it's it's a very low-level tactical tool for one team but they are trying to be honnest about their uncertainty that's what I that's why I liked and included this graph but they're not this is not I don't mean to say anything mean about the people who are behind it but this graph is not honest it's it's a caricature of reality and it's not meant it's not even meant to have you think about reality on the contrary it is meant to discourage conversation it is meant as a weapon against managers when they ask for estimates so instead of having a conversation about why so if I could give you an estimate what would you do with it and is there some other way that we can satisfy your concerns or lay your concerns and so on and so that's that's a good conversation to have instead what I used to do I was I was taken for a ride I was tricked what I used to do was I would tell my managers no I cannot give you I will not give you an estimate because the kind of uncertainty so I was shielding myself and my thinking about software development behind someone else's authority Steve McConnell says Connor therefore I will not give you an estimate that's a very I think it's a very unproductive unconstructive thing to do another question no that's an easy question no we don't we don't care about we don't we especially do not care about the average cost of fixing a defect because what's it what does mean if what does it even mean to take an average because one bug is going to cost us one minute to fix and maybe 10 10 cents and one bug is going to kill the company so and that would be you know a black swan what what do we care the average that doesn't make sense it doesn't make sense to add up all the bugs and divide by the number of bugs that has you know it's a mathematical operation so yes in that sense it you can do it with a calculator but it has absolutely no meaning whatsoever so you might you might want to ask yourself it is is the reasoning behind that contract actually based on on validated experiment I don't know but okay but so you may be lucky in that in that respect I think one problem that we face I will close with that is that many of the contractual assumptions so many of the hypothesis if you will that the contractual relationships that the very very street structuring constraints that we operate under are based on maybe leprechauns and that's you know that to me that's kind of a big deal if if we find out that we were operating under a false assumption we will want to revise the way we do things I'm going to close with that I'm going to thank you again and I'm around if you want to talk about this a little more but it's time for me to let you go thank you 